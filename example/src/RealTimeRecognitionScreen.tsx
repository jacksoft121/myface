import 'react-native-worklets-core';
import React, { useCallback, useEffect, useMemo, useRef, useState } from 'react';
import {
  ActivityIndicator,
  Dimensions,
  Platform,
  StyleSheet,
  Text,
  TouchableOpacity,
  View,
} from 'react-native';
import { useFocusEffect, useIsFocused } from '@react-navigation/native';

import {
  BoxedInspireFace,
  CameraRotation,
  DetectMode,
  InspireFace,
} from 'react-native-nitro-inspire-face';
import { NitroModules } from 'react-native-nitro-modules';

import {
  Camera,
  useCameraDevice,
  useFrameProcessor,
  runAtTargetFps,
  type Frame,
} from 'react-native-vision-camera';
import { useResizePlugin } from 'vision-camera-resize-plugin';

import {
  check,
  request,
  openSettings,
  PERMISSIONS,
  RESULTS,
} from 'react-native-permissions';

import { Worklets } from 'react-native-worklets-core';
import { Canvas, Rect, Text as SkiaText, useFont } from '@shopify/react-native-skia';
import { useSharedValue } from 'react-native-reanimated';

import { type RegisteredFacesDTO, type FaceBoxBuf, type FaceBoxUI } from './dto/DlxTypes';
import { STORAGE_KEYS, userInfoCacheStorage } from './comm/GlobalStorage';
import { log } from './comm/logger';

// ====== åª launch ä¸€æ¬¡ ======
const gAny: any = globalThis as any;
if (!gAny.__IFACE_LAUNCHED) {
  InspireFace.launch('Pikachu');
  gAny.__IFACE_LAUNCHED = true;
}

// ====== å¸¸é‡ ======
const { width: PREVIEW_W, height: PREVIEW_H } = Dimensions.get('window');

// åˆ†æåˆ†è¾¨ç‡ï¼ˆå’Œä½  Kotlin ç›®æ ‡ä¸€è‡´ï¼‰
const SRC_W = 640;
const SRC_H = 480;

// Skiaï¼šç”¨ number è‰²å€¼
const COLOR_GREEN = 0xff00ff00;
const COLOR_RED = 0xffff0000;
const BG_GREEN = 0xd900ff00;
const BG_RED = 0xd9ff0000;
const BG_BLACK50 = 0x80000000;
const COLOR_WHITE = 0xffffffff;
const COLOR_BLACK = 0xff000000;

// ====== Permission ======
function getCameraPermissionConst() {
  return Platform.select({
    ios: PERMISSIONS.IOS.CAMERA,
    android: PERMISSIONS.ANDROID.CAMERA,
    default: PERMISSIONS.ANDROID.CAMERA,
  });
}

// ====== worklet-safe helpers ======
function clamp(n: number, min: number, max: number) {
  'worklet';
  return Math.max(min, Math.min(max, n));
}

// â€œå›¾åƒåæ ‡(srcW/srcH)â€ â†’ â€œå±å¹• contain åæ ‡â€
function mapRectToViewContain(
  b: { x: number; y: number; width: number; height: number },
  srcW: number,
  srcH: number,
  viewW: number,
  viewH: number
) {
  'worklet';
  const scale = Math.min(viewW / srcW, viewH / srcH);
  const scaledW = srcW * scale;
  const scaledH = srcH * scale;
  const offsetX = (viewW - scaledW) / 2;
  const offsetY = (viewH - scaledH) / 2;

  const x = b.x * scale + offsetX;
  const y = b.y * scale + offsetY;
  const w = b.width * scale;
  const h = b.height * scale;

  return {
    x: clamp(x, -viewW, viewW * 2),
    y: clamp(y, -viewH, viewH * 2),
    width: clamp(w, 0, viewW * 2),
    height: clamp(h, 0, viewH * 2),
  };
}

// frame.rotation(ä¼˜å…ˆ) / frame.orientation(å…œåº•) â†’ rotationDegrees
function getFrameRotationDegrees(frame: Frame) {
  'worklet';
  const r = frame.rotation;
  if (typeof r === 'number') return r; // 0/90/180/270

  // å…œåº•ï¼šorientation string
  switch (frame.orientation) {
    case 'portrait': return 0;
    case 'portrait-upside-down': return 180;
    case 'landscape-left': return 90;
    case 'landscape-right': return 270;
    default: return 0;
  }
}

// rotationDegrees â†’ InspireFace CameraRotation
function toCameraRotation(deg: number) {
  'worklet';
  const d = ((deg % 360) + 360) % 360;
  if (d === 90) return CameraRotation.ROTATION_90;
  if (d === 180) return CameraRotation.ROTATION_180;
  if (d === 270) return CameraRotation.ROTATION_270;
  return CameraRotation.ROTATION_0;
}

// ç»™å®š rotationDegreesï¼Œupright çš„å®½é«˜
function uprightSizeForRotation(deg: number) {
  'worklet';
  const d = ((deg % 360) + 360) % 360;
  if (d === 90 || d === 270) return { w: SRC_H, h: SRC_W };
  return { w: SRC_W, h: SRC_H };
}

/**
 * âœ… å…³é”®ï¼šè‡ªåŠ¨é€‰â€œrect åæ ‡å˜æ¢æ¨¡å¼â€ï¼Œä¸“æ²»ä½ è¿™ä¸ªâ€œå¯¹è§’çº¿åâ€
 * - æˆ‘ä»¬ä¸çŸ¥é“ SDK rect å±äºå“ªå¥—åæ ‡ï¼ˆæ˜¯å¦è½¬è¿‡/æ˜¯å¦è½´äº’æ¢/æ˜¯å¦åŸç‚¹ç¿»ï¼‰
 * - æ‰€ä»¥ä¸€å¸§é‡Œå°è¯• 8 ç§æ¨¡å¼ï¼ˆ4ä¸ªæ—‹è½¬ * æ˜¯å¦transposeï¼‰
 * - é€‰â€œè½åœ¨ç”»é¢å†…æœ€å¤šâ€çš„é‚£ä¸ªä½œä¸ºæœ¬å¸§çš„ rect ä¿®æ­£æ¨¡å¼
 */
function transformRectMode(
  rect: { x: number; y: number; width: number; height: number },
  baseW: number,
  baseH: number,
  mode: number
) {
  'worklet';
  let x = rect.x, y = rect.y, w = rect.width, h = rect.height;

  // mode: 0..3 = rotate 0/90/180/270
  // mode: 4..7 = transpose + rotate 0/90/180/270
  const transpose = mode >= 4;
  const rot = mode % 4;

  if (transpose) {
    // å¯¹è§’çº¿åï¼šswap x<->y & w<->h
    const tx = y; const ty = x;
    const tw = h; const th = w;
    x = tx; y = ty; w = tw; h = th;

    // transpose åï¼Œåæ ‡åŸºå‡†ä¹Ÿç›¸å½“äºäº¤æ¢
    const tmp = baseW; baseW = baseH; baseH = tmp;
  }

  // å†åšæ—‹è½¬ï¼ˆæŠŠâ€œæŸåæ ‡ç³»â€è½¬åˆ° uprightï¼‰
  // æ³¨æ„ï¼šè¿™é‡Œç”¨ baseW/baseH åšæ—‹è½¬å…¬å¼
  if (rot === 0) {
    return { x, y, width: w, height: h, outW: baseW, outH: baseH };
  }

  if (rot === 1) {
    // rotate 90 CW
    // (x, y) -> (baseH - (y+h), x)
    return {
      x: baseH - (y + h),
      y: x,
      width: h,
      height: w,
      outW: baseH,
      outH: baseW,
    };
  }

  if (rot === 2) {
    // rotate 180
    return {
      x: baseW - (x + w),
      y: baseH - (y + h),
      width: w,
      height: h,
      outW: baseW,
      outH: baseH,
    };
  }

  // rot === 3 : rotate 270 CW (or 90 CCW)
  return {
    x: y,
    y: baseW - (x + w),
    width: h,
    height: w,
    outW: baseH,
    outH: baseW,
  };
}

function scoreRectInBounds(
  r: { x: number; y: number; width: number; height: number },
  W: number,
  H: number
) {
  'worklet';
  const cx = r.x + r.width * 0.5;
  const cy = r.y + r.height * 0.5;
  let s = 0;

  if (r.width > 4 && r.height > 4) s += 1;
  if (r.width < W * 1.2 && r.height < H * 1.2) s += 1;
  if (cx >= 0 && cx <= W && cy >= 0 && cy <= H) s += 3;

  // è½»å¾®æƒ©ç½šç¦»è°±å€¼
  if (r.x < -W || r.y < -H || r.x > 2 * W || r.y > 2 * H) s -= 2;

  return s;
}

function normalizeRectToPx(rect: any, W: number, H: number) {
  'worklet';
  let x = Number(rect?.x ?? 0);
  let y = Number(rect?.y ?? 0);
  let w = Number(rect?.width ?? 0);
  let h = Number(rect?.height ?? 0);

  // å…¼å®¹ 0~1
  if (w <= 1.5 && h <= 1.5) {
    x *= W; y *= H; w *= W; h *= H;
  }

  return {
    x, y,
    width: w,
    height: h,
  };
}

// format é€‰æ‹©ï¼ˆå¯ç•™å¯åˆ ï¼‰
function pickBestFormat(device: any) {
  if (!device?.formats?.length) return undefined;
  const targetArea = SRC_W * SRC_H;

  let best = device.formats[0];
  let bestScore = Number.POSITIVE_INFINITY;

  for (const f of device.formats) {
    const area = (f.videoWidth ?? 0) * (f.videoHeight ?? 0);
    const areaDiff = Math.abs(area - targetArea);
    const maxFps = f.maxFps ?? 30;
    const score = areaDiff - maxFps * 1000;
    if (score < bestScore) {
      bestScore = score;
      best = f;
    }
  }
  return best;
}

export default function RealTimeRecognitionScreen() {
  const [cameraType, setCameraType] = useState<'front' | 'back'>('front');
  const device = useCameraDevice(cameraType);
  const camera = useRef<Camera>(null);
  const { resize } = useResizePlugin();

  const [hubFaceCount, setHubFaceCount] = useState(0);
  const [hasPermission, setHasPermission] = useState<boolean | null>(null);
  const [boxes, setBoxes] = useState<FaceBoxUI[]>([]);
  const [isCameraActive, setIsCameraActive] = useState(false);

  const canvasSize = useSharedValue({ width: PREVIEW_W, height: PREVIEW_H });
  const font = useFont(require('./assets/fonts/PingFangSC-Regular.ttf'), 18);

  const [cameraInitialized, setCameraInitialized] = useState(false);
  const isFocused = useIsFocused();

  const [debug, setDebug] = useState({
    faceCount: 0,
    rotDeg: 0,
    chosenMode: 0,
    base: `${SRC_W}x${SRC_H}`,
    upright: `0x0`,
  });

  // ğŸ”§ æ–°å¢ï¼šé˜²æ­¢é‡å¤åˆå§‹åŒ– Session
  const sessionRef = useRef<any>(null);

  // æƒé™
  useFocusEffect(
    useCallback(() => {
      const requestPermission = async () => {
        const perm = getCameraPermissionConst();
        if (!perm) return setHasPermission(false);

        const st0 = await check(perm);
        if (st0 === RESULTS.GRANTED || st0 === RESULTS.LIMITED) {
          setHasPermission(true);
        } else {
          const st1 = await request(perm);
          setHasPermission(st1 === RESULTS.GRANTED || st1 === RESULTS.LIMITED);
        }
      };
      requestPermission();

      // ğŸ”§ ç»„ä»¶å¤±ç„¦æ—¶æ¸…ç†çŠ¶æ€
      return () => {
        setIsCameraActive(false);
        setBoxes([]);
        smoothRef.current.clear();
      };
    }, [])
  );

  // åŒæ­¥æ³¨å†Œåº“
  useEffect(() => {
    if (!isFocused || !hasPermission) return;

    const loadRegisteredFaces = async () => {
      try {
        const allKeys = userInfoCacheStorage.getAllKeys();
        let cnt = 0;

        for (const key of allKeys) {
          const jsonString = userInfoCacheStorage.getString(key);
          if (!jsonString) continue;

          if (key === STORAGE_KEYS.REGISTERED_FACES) {
            const faces: RegisteredFacesDTO[] = JSON.parse(jsonString);
            cnt += faces.length;
          } else {
            try {
              const userData: RegisteredFacesDTO = JSON.parse(jsonString);
              if (userData?.faceId && userData.name) cnt += 1;
            } catch (e) {
              log(`è§£æç”¨æˆ·æ•°æ®å¤±è´¥: ${key}`, e);
            }
          }
        }

        const hubCount = InspireFace.featureHubGetFaceCount();
        setHubFaceCount(hubCount);
        log(`Reloaded faces: ${cnt}, hubCount: ${hubCount}`);
      } catch (e) {
        console.warn('Reload faces error:', e);
        log('Reload faces error:', e);
      }
    };

    loadRegisteredFaces();
  }, [isFocused, hasPermission]);

  // ğŸ”§ ä¿®å¤ï¼šSession åˆå§‹åŒ–é€»è¾‘ï¼ˆé˜²æ­¢é‡å¤åˆ›å»ºï¼‰
  const boxedSession = useMemo(() => {
    if (sessionRef.current) return sessionRef.current;

    try {
      const s = InspireFace.createSession(
        { enableRecognition: true, enableFaceQuality: true },
        DetectMode.ALWAYS_DETECT,
        5,
        -1,
        15 // ğŸ”§ é™åˆ¶è·Ÿè¸ªå¸§ç‡ï¼Œé™ä½æ€§èƒ½æ¶ˆè€—
      );
      s.setTrackPreviewSize(320);
      s.setFaceDetectThreshold(0.6); // ğŸ”§ æé«˜æ£€æµ‹é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ£€
      s.setTrackModeSmoothRatio(0.7);
      s.setTrackModeDetectInterval(10);
      s.setFilterMinimumFacePixelSize(50);

      const boxed = NitroModules.box(s);
      sessionRef.current = boxed;
      return boxed;
    } catch (e) {
      log('åˆ›å»º Session å¤±è´¥:', e);
      throw e;
    }
  }, []);

  // ğŸ”§ ä¿®å¤ï¼šç»„ä»¶å¸è½½æ—¶é‡Šæ”¾ Session
  useEffect(() => {
    return () => {
      if (sessionRef.current) {
        try {
          const session = sessionRef.current.unbox();
          session?.dispose();
          sessionRef.current = null;
        } catch (e) {
          log('é‡Šæ”¾ Session å¤±è´¥:', e);
        }
      }
      gAny.__IFACE_LAUNCHED = false;
    };
  }, []);

  const format = useMemo(() => pickBestFormat(device), [device]);

  // JS å¹³æ»‘
  const smoothRef = useRef(new Map<number, FaceBoxUI>());

  // ğŸ”§ ä¼˜åŒ–ï¼šé˜²æŠ–é€»è¾‘ + ç±»å‹å®‰å…¨
  const reportFacesToJS = useMemo(() => {
    let lastReportTime = 0;
    return Worklets.createRunOnJS(
      (payload: {
        faceCount: number;
        rotDeg: number;
        chosenMode: number;
        uprightW: number;
        uprightH: number;
        faces: FaceBoxBuf[];
      }) => {
        // é˜²æŠ–ï¼š66ms å†…åªæ›´æ–°ä¸€æ¬¡ï¼ˆçº¦15fpsï¼‰
        const now = Date.now();
        if (now - lastReportTime < 66) return;
        lastReportTime = now;

        setDebug({
          faceCount: payload.faceCount,
          rotDeg: payload.rotDeg,
          chosenMode: payload.chosenMode,
          base: `${SRC_W}x${SRC_H}`,
          upright: `${payload.uprightW}x${payload.uprightH}`,
        });

        const alpha = 0.35;

        const next: FaceBoxUI[] = payload.faces.map((b) => {
          const mapped = mapRectToViewContain(b, payload.uprightW, payload.uprightH, PREVIEW_W, PREVIEW_H);

          const id = b.trackId ?? 0;
          const prev = smoothRef.current.get(id);

          const smoothed = prev
            ? {
              x: prev.x + (mapped.x - prev.x) * alpha,
              y: prev.y + (mapped.y - prev.y) * alpha,
              width: prev.width + (mapped.width - prev.width) * alpha,
              height: prev.height + (mapped.height - prev.height) * alpha,
            }
            : mapped;

          const ui: FaceBoxUI = {
            ...smoothed,
            id,
            name: b.name,
            confidence: b.confidence,
            isMatched: b.isMatched,
          };

          smoothRef.current.set(id, ui);
          return ui;
        });

        // æ¸…ç†è¿‡æœŸçš„ trackId
        const aliveIds = new Set(next.map((n) => n.id));
        smoothRef.current.forEach((_, key) => {
          if (!aliveIds.has(key)) smoothRef.current.delete(key);
        });

        setBoxes(next);
      }
    );
  }, []);

  // ğŸ”§ æ ¸å¿ƒä¿®å¤ï¼šFrameProcessor æ€§èƒ½ + é”™è¯¯å¤„ç† + ç±»å‹å®‰å…¨
  const frameProcessor = useFrameProcessor(
    (frame: Frame) => {
      'worklet';

      const g: any = globalThis as any;
      if (g.__dlx_busy) return;
      g.__dlx_busy = true;

      try {
        // ğŸ”§ é™ä½å¤„ç†å¸§ç‡åˆ°15fpsï¼Œå¹³è¡¡æ€§èƒ½å’Œä½“éªŒ
        runAtTargetFps(15, () => {
          'worklet';

          let bitmap: any = null;
          let imageStream: any = null;

          try {
            // âœ… åª resizeï¼Œä¸æ—‹è½¬ã€ä¸é•œåƒï¼ˆé¿å…åæ ‡ç³»æä¹±ï¼‰
            const resized = resize(frame, {
              scale: { width: SRC_W, height: SRC_H },
              rotation: '0deg',
              pixelFormat: 'bgr',
              dataType: 'uint8',
              mirror: false,
            });

            if (!resized || !resized.buffer) {
              console.error('[Worklet] Resize æ’ä»¶è¿”å›ç©ºæ•°æ®');
              reportFacesToJS({
                faceCount: 0,
                rotDeg: 0,
                chosenMode: 0,
                uprightW: SRC_W,
                uprightH: SRC_H,
                faces: [],
              });
              return;
            }

            // ç”¨ frame çš„çœŸå®æ—‹è½¬å‘Šè¯‰ InspireFace
            const rotDeg = getFrameRotationDegrees(frame);
            const camRot = toCameraRotation(rotDeg);

            // upright å°ºå¯¸ï¼ˆç”¨äºæœ€ç»ˆç”»æ¡†åæ ‡ç³»ï¼‰
            const upright = uprightSizeForRotation(rotDeg);
            const uprightW = upright.w;
            const uprightH = upright.h;

            const unboxed = BoxedInspireFace.unbox();
            if (!unboxed) {
              console.error('[Worklet] æ— æ³•è·å– InspireFace å®ä¾‹');
              reportFacesToJS({
                faceCount: 0,
                rotDeg,
                chosenMode: 0,
                uprightW,
                uprightH,
                faces: [],
              });
              return;
            }

            // ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨åŠ¨æ€è®¡ç®—çš„å°ºå¯¸åˆ›å»º bitmap
            bitmap = unboxed.createImageBitmapFromBuffer(
              resized.buffer as ArrayBuffer,
              SRC_W,
              SRC_H,
              3 // BGR é€šé“æ•°
            );

            imageStream = unboxed.createImageStreamFromBitmap(bitmap, camRot);

            const session = boxedSession.unbox();
            if (!session) {
              console.error('[Worklet] Session æœªåˆå§‹åŒ–');
              reportFacesToJS({
                faceCount: 0,
                rotDeg,
                chosenMode: 0,
                uprightW,
                uprightH,
                faces: [],
              });
              return;
            }

            const facesAny: any = session.executeFaceTrack(imageStream);

            // ğŸ”§ å…¼å®¹ä¸åŒçš„è¿”å›æ ¼å¼
            const faceCount = (() => {
              if (!facesAny) return 0;
              if (typeof facesAny.length === 'number') return facesAny.length;
              if (typeof facesAny.detectedNum === 'number') return facesAny.detectedNum;
              return 0;
            })();

            if (faceCount <= 0) {
              reportFacesToJS({
                faceCount: 0,
                rotDeg,
                chosenMode: 0,
                uprightW,
                uprightH,
                faces: [],
              });
              return;
            }

            // å…ˆæ”¶é›† raw rectï¼ˆæœ€å¤šå–å‰3ä¸ªç”¨æ¥é€‰æ¨¡å¼ï¼‰
            const rawRects: { x: number; y: number; width: number; height: number }[] = [];

            for (let i = 0; i < faceCount && i < 3; i++) {
              const f = facesAny[i] ?? {
                token: facesAny.tokens?.[i],
                rect: facesAny.rects?.[i],
                trackId: facesAny.trackIds?.[i] ?? facesAny.ids?.[i],
              };

              if (!f?.rect) continue;
              rawRects.push(normalizeRectToPx(f.rect, SRC_W, SRC_H));
            }

            // âœ… é€‰æœ€åŒ¹é…çš„æ¨¡å¼ï¼ˆ8ç§ï¼‰
            let bestMode = 0;
            let bestScore = -999999;

            for (let mode = 0; mode < 8; mode++) {
              let s = 0;
              for (let i = 0; i < rawRects.length; i++) {
                const tr = transformRectMode(rawRects[i], SRC_W, SRC_H, mode);
                // tr.outW/outH æ˜¯è¯¥æ¨¡å¼ä¸‹çš„åæ ‡ç©ºé—´å°ºå¯¸
                // æˆ‘ä»¬æœ€ç»ˆè¦çš„æ˜¯ uprightW/uprightHï¼Œæ‰€ä»¥åªç»™â€œå°ºå¯¸ä¸€è‡´â€çš„æ¨¡å¼æ›´é«˜åˆ†
                const sizeMatch = (tr.outW === uprightW && tr.outH === uprightH) ? 2 : 0;
                s += scoreRectInBounds(tr, tr.outW, tr.outH) + sizeMatch;
              }
              if (s > bestScore) {
                bestScore = s;
                bestMode = mode;
              }
            }

            // ç”Ÿæˆæœ€ç»ˆ boxesï¼ˆåœ¨ upright åæ ‡ç³»ï¼‰
            const out: FaceBoxBuf[] = [];

            for (let i = 0; i < faceCount; i++) {
              const f = facesAny[i] ?? {
                token: facesAny.tokens?.[i],
                rect: facesAny.rects?.[i],
                trackId: facesAny.trackIds?.[i] ?? facesAny.ids?.[i],
              };

              if (!f?.rect || !f?.token) continue;

              const raw = normalizeRectToPx(f.rect, SRC_W, SRC_H);
              const tr = transformRectMode(raw, SRC_W, SRC_H, bestMode);

              // âœ… å‰æ‘„ï¼šåªåœ¨â€œç”»æ¡†åæ ‡ç³»â€åšé•œåƒï¼ˆä¸ <Camera isMirrored> ä¿æŒä¸€è‡´ï¼‰
              const mirrorUI = cameraType === 'front';
              let fx = tr.x;
              if (mirrorUI) fx = tr.outW - (tr.x + tr.width);

              // clamp é˜²æ­¢è¶Šç•Œ
              const bx = clamp(fx, -tr.outW, tr.outW * 2);
              const by = clamp(tr.y, -tr.outH, tr.outH * 2);
              const bw = clamp(tr.width, 0, tr.outW * 2);
              const bh = clamp(tr.height, 0, tr.outH * 2);

              // ğŸ”§ å¢åŠ é”™è¯¯å¤„ç†ï¼šé˜²æ­¢ç‰¹å¾æå–å¤±è´¥
              let feature: any = null;
              let searched: any = null;
              try {
                feature = session.extractFaceFeature(imageStream, f.token);
                searched = unboxed.featureHubFaceSearch(feature);
              } catch (e) {
                console.error(`[Worklet] æå–ç‰¹å¾å¤±è´¥: ${e?.message}`);
                searched = { name: 'è¯†åˆ«å¤±è´¥', confidence: 0 };
              }

              const name = searched?.name || 'æœªæ³¨å†Œ';
              const confidence = searched?.confidence || 0;
              const isMatched = !!(searched?.name && confidence > 0.5);

              out.push({
                x: bx,
                y: by,
                width: bw,
                height: bh,
                trackId: Number(f.trackId ?? i),
                name,
                confidence,
                isMatched,
              });
            }

            reportFacesToJS({
              faceCount,
              rotDeg,
              chosenMode: bestMode,
              uprightW,
              uprightH,
              faces: out,
            });
          } catch (e: any) {
            console.error('[Worklet] FaceTrack å¤„ç†å¤±è´¥:', e?.message ?? e);
            reportFacesToJS({
              faceCount: 0,
              rotDeg: 0,
              chosenMode: 0,
              uprightW: SRC_W,
              uprightH: SRC_H,
              faces: [],
            });
          } finally {
            // ğŸ”§ ç¡®ä¿èµ„æºé‡Šæ”¾
            try { if (imageStream) imageStream.dispose(); } catch (e) {}
            try { if (bitmap) bitmap.dispose(); } catch (e) {}
          }
        });
      } finally {
        g.__dlx_busy = false;
      }
    },
    [resize, boxedSession, reportFacesToJS, cameraType]
  );

  // ğŸ”§ ä¼˜åŒ–ï¼šåˆ‡æ¢æ‘„åƒå¤´æ—¶é‡ç½®çŠ¶æ€
  const toggleCamera = useCallback(() => {
    setCameraType((p) => (p === 'front' ? 'back' : 'front'));
    setBoxes([]);
    smoothRef.current.clear();
  }, []);

  const startRecognition = useCallback(() => {
    if (cameraInitialized) {
      setIsCameraActive(true);
    }
  }, [cameraInitialized]);

  const stopRecognition = useCallback(() => {
    setIsCameraActive(false);
    setBoxes([]);
    smoothRef.current.clear();
  }, []);

  if (hasPermission === null) {
    return (
      <View style={styles.container}>
        <ActivityIndicator size="large" color="#ffffff" />
        <Text style={styles.text}>Requesting camera permission...</Text>
      </View>
    );
  }

  if (!hasPermission) {
    return (
      <View style={styles.container}>
        <Text style={styles.text}>Camera permission not granted.</Text>
        <TouchableOpacity onPress={() => openSettings()}>
          <Text style={styles.linkText}>Open Settings</Text>
        </TouchableOpacity>
      </View>
    );
  }

  if (!device) {
    return (
      <View style={styles.container}>
        <Text style={styles.text}>No camera device found.</Text>
      </View>
    );
  }

  return (
    <View style={styles.container}>
      <Camera
        ref={camera}
        style={StyleSheet.absoluteFill}
        device={device}
        isActive={isFocused && cameraInitialized && isCameraActive}
        format={format}
        frameProcessor={frameProcessor}
        frameProcessorFps={15} // ğŸ”§ åŒ¹é…å¤„ç†å¸§ç‡
        resizeMode="contain"
        zoom={0}
        isMirrored={cameraType === 'front'}
        onInitialized={() => setCameraInitialized(true)}
        onError={(error) => {
          log('Camera é”™è¯¯:', error);
          setIsCameraActive(false);
        }}
      />

      {/* ğŸ”§ ä¿®å¤ï¼šCanvas å°ºå¯¸åŒæ­¥ + é˜²æ­¢ç©ºæ¸²æŸ“ */}
      <Canvas style={StyleSheet.absoluteFill} onSize={(size) => {
        canvasSize.value = size;
      }}>
        {boxes.map((b) => {
          let label = b.name || `ID:${b.id}`;
          if (b.isMatched && b.confidence) label += ` (${(b.confidence * 100).toFixed(1)}%)`;

          const boxColor = b.isMatched ? COLOR_GREEN : COLOR_RED;
          const bgColor = b.isMatched ? BG_GREEN : BG_RED;
          const textColor = b.isMatched ? COLOR_BLACK : COLOR_WHITE;

          if (!font) return null;

          const padX = 6;
          const padY = 4;
          const textW = font.getTextWidth(label) + padX * 2;
          const textH = font.getSize() + padY * 2 + 6;
          const bgX = b.x;
          const bgY = Math.max(0, b.y - textH - 6);

          return (
            <React.Fragment key={`face-box-${b.id}`}>
              <Rect
                x={b.x}
                y={b.y}
                width={b.width}
                height={b.height}
                color={boxColor}
                style="stroke"
                strokeWidth={3}
              />
              <Rect x={bgX} y={bgY} width={textW} height={textH} color={bgColor} />
              <SkiaText
                x={bgX + padX}
                y={bgY + textH - padY - 4}
                text={label}
                font={font}
                color={textColor}
              />
            </React.Fragment>
          );
        })}

        {/* è°ƒè¯•ä¿¡æ¯ */}
        {font && (
          <>
            <Rect x={10} y={40} width={390} height={30} color={BG_BLACK50} />
            <SkiaText
              x={20}
              y={65}
              text={`hub:${hubFaceCount} faces:${debug.faceCount} rot:${debug.rotDeg} mode:${debug.chosenMode} base:${debug.base} up:${debug.upright}`}
              font={font}
              color={COLOR_WHITE}
            />
          </>
        )}
      </Canvas>

      <View style={styles.controlsContainer}>
        <TouchableOpacity style={styles.button} onPress={toggleCamera}>
          <Text style={styles.buttonText}>åˆ‡æ¢</Text>
        </TouchableOpacity>

        {!isCameraActive ? (
          <TouchableOpacity style={[styles.button, styles.primaryButton]} onPress={startRecognition}>
            <Text style={styles.buttonText}>å¼€å§‹</Text>
          </TouchableOpacity>
        ) : (
          <TouchableOpacity style={[styles.button, styles.dangerButton]} onPress={stopRecognition}>
            <Text style={styles.buttonText}>åœæ­¢</Text>
          </TouchableOpacity>
        )}
      </View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: { flex: 1, justifyContent: 'center', alignItems: 'center', backgroundColor: 'black' },
  text: { color: 'white', fontSize: 16, marginTop: 10 },
  linkText: { color: '#007AFF', fontSize: 16, marginTop: 10 },
  controlsContainer: {
    position: 'absolute',
    bottom: 40,
    left: 0,
    right: 0,
    flexDirection: 'row',
    justifyContent: 'space-around',
  },
  button: {
    backgroundColor: 'rgba(128,128,128,0.8)',
    paddingHorizontal: 20,
    paddingVertical: 15,
    borderRadius: 30,
    minWidth: 100,
    alignItems: 'center',
  },
  buttonText: { color: 'white', fontSize: 16, fontWeight: 'bold' },
  primaryButton: { backgroundColor: 'rgba(0, 122, 255, 0.8)' },
  dangerButton: { backgroundColor: 'rgba(255, 59, 48, 0.8)' },
});
